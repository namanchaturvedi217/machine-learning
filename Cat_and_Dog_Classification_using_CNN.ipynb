{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pW9eL4DAs1tV",
        "outputId": "f75bf590-1359-40da-d92f-1152ee1f427f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'GV_DeepLearning' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone \"https://github.com/vadivukar/GV_DeepLearning/\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/laxmimerit/dog-cat-full-dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wYRaJ8rs_XT",
        "outputId": "55fabd25-b993-4e8d-e434-ec31549f0148"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'dog-cat-full-dataset' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "PCf8Qcfws_tM"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "BEvyk1LjtCNU"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "shear_range = 0.2,\n",
        "zoom_range = 0.2,\n",
        "horizontal_flip = True)\n",
        "\n",
        "training_set = train_datagen.flow_from_directory('/content/dog-cat-full-dataset/data/train',\n",
        "target_size = (64, 64),\n",
        "batch_size = 32,\n",
        "class_mode = 'binary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9LgNgsWZtHQ3",
        "outputId": "f8e09b05-e1a2-48ca-b70f-be4deb570fdb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "test_set = test_datagen.flow_from_directory('/content/dog-cat-full-dataset/data/test',\n",
        "target_size = (64, 64),\n",
        "batch_size = 32,\n",
        "class_mode = 'binary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RObJGHJUtK5J",
        "outputId": "88efce37-bc0a-4ff5-c4a0-ee2b7264f20c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = tf.keras.models.Sequential()"
      ],
      "metadata": {
        "id": "XekvD0FItgbr"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu',\n",
        "input_shape=[64, 64, 3]))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
        "cnn.add(tf.keras.layers.Flatten())\n",
        "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
        "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
        "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n"
      ],
      "metadata": {
        "id": "WBPud58QtNVw"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.fit(x = training_set, validation_data = test_set, epochs = 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5jqdrBgtRTG",
        "outputId": "f06ffe43-f59a-451e-a7b1-411b3eabf965"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "625/625 [==============================] - 221s 351ms/step - loss: 0.6215 - accuracy: 0.6442 - val_loss: 0.5555 - val_accuracy: 0.7120\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 200s 319ms/step - loss: 0.5350 - accuracy: 0.7319 - val_loss: 0.5005 - val_accuracy: 0.7512\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 212s 338ms/step - loss: 0.4975 - accuracy: 0.7595 - val_loss: 0.4619 - val_accuracy: 0.7826\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 198s 317ms/step - loss: 0.4738 - accuracy: 0.7737 - val_loss: 0.4462 - val_accuracy: 0.7880\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 201s 322ms/step - loss: 0.4516 - accuracy: 0.7868 - val_loss: 0.4387 - val_accuracy: 0.7918\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 199s 318ms/step - loss: 0.4344 - accuracy: 0.7972 - val_loss: 0.4153 - val_accuracy: 0.8070\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 202s 324ms/step - loss: 0.4171 - accuracy: 0.8048 - val_loss: 0.4126 - val_accuracy: 0.8040\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 199s 319ms/step - loss: 0.4053 - accuracy: 0.8151 - val_loss: 0.4104 - val_accuracy: 0.8144\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 202s 323ms/step - loss: 0.3920 - accuracy: 0.8233 - val_loss: 0.4117 - val_accuracy: 0.8060\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 218s 349ms/step - loss: 0.3824 - accuracy: 0.8298 - val_loss: 0.4147 - val_accuracy: 0.8096\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff8a22a71f0>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    }
  ]
}